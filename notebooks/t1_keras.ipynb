{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn import preprocessing\n",
    "from keras import models, layers, regularizers\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from utils import path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nAcid', 'ALogP', 'ALogp2', 'AMR', 'apol', 'naAromAtom', 'nAromBond',\n",
      "       'nAtom', 'nHeavyAtom', 'nH',\n",
      "       ...\n",
      "       'MW', 'WTPT-1', 'WTPT-2', 'WTPT-3', 'WTPT-4', 'WTPT-5', 'WPATH', 'WPOL',\n",
      "       'XLogP', 'Zagreb'],\n",
      "      dtype='object', length=729)\n",
      "(1974, 730)\n",
      "(1974, 729)\n",
      "(1974,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 128)               93440     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 105,921\n",
      "Trainable params: 105,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "molecular_descriptor = pd.read_csv(path.molecular_descriptor_train_path)\n",
    "molecular_descriptor = molecular_descriptor.drop(labels = 'SMILES', axis = 1)\n",
    "\n",
    "head = molecular_descriptor.columns\n",
    "print(head)\n",
    "\n",
    "era_activity = pd.read_csv(path.era_activity_train_path)\n",
    "era_activity = era_activity.drop(labels = 'SMILES', axis = 1)\n",
    "\n",
    "# print(molecular_descriptor.values.shape)\n",
    "# print(era_activity.values.shape)\n",
    "\n",
    "dataset_df = molecular_descriptor\n",
    "dataset_df['pIC50'] = era_activity['pIC50']\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dataset = min_max_scaler.fit_transform(dataset_df.values)\n",
    "print(dataset.shape)\n",
    "\n",
    "x_train = dataset[:, 0:dataset.shape[1] - 1]\n",
    "y_train = dataset[:, -1]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate the same model multiple times,（因为需要将同一个模型多次实例化，）\n",
    "    # we use a function to construct it.（所以用一个函数来构建模型）\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation = 'relu',\n",
    "                           input_shape = (x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation = 'relu',\n",
    "                           input_shape = (x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "lr_reduce = ReduceLROnPlateau(monitor = 'loss', factor = 0.5, patience = 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1579 samples, validate on 395 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 0.0186 - mean_absolute_error: 0.1042 - val_loss: 0.0231 - val_mean_absolute_error: 0.1263\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.0110 - mean_absolute_error: 0.0794 - val_loss: 0.0272 - val_mean_absolute_error: 0.1394\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.0098 - mean_absolute_error: 0.0750 - val_loss: 0.0254 - val_mean_absolute_error: 0.1353\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.0092 - mean_absolute_error: 0.0723 - val_loss: 0.0285 - val_mean_absolute_error: 0.1425\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.0089 - mean_absolute_error: 0.0711 - val_loss: 0.0278 - val_mean_absolute_error: 0.1395\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.0087 - mean_absolute_error: 0.0711 - val_loss: 0.0267 - val_mean_absolute_error: 0.1371\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.0078 - mean_absolute_error: 0.0666 - val_loss: 0.0252 - val_mean_absolute_error: 0.1288\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.0082 - mean_absolute_error: 0.0689 - val_loss: 0.0263 - val_mean_absolute_error: 0.1347\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.0072 - mean_absolute_error: 0.0639 - val_loss: 0.0266 - val_mean_absolute_error: 0.1374\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.0071 - mean_absolute_error: 0.0628 - val_loss: 0.0246 - val_mean_absolute_error: 0.1303\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.0069 - mean_absolute_error: 0.0621 - val_loss: 0.0242 - val_mean_absolute_error: 0.1301\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.0071 - mean_absolute_error: 0.0650 - val_loss: 0.0232 - val_mean_absolute_error: 0.1258\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.0067 - mean_absolute_error: 0.0617 - val_loss: 0.0241 - val_mean_absolute_error: 0.1272\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.0067 - mean_absolute_error: 0.0618 - val_loss: 0.0235 - val_mean_absolute_error: 0.1271\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.0066 - mean_absolute_error: 0.0602 - val_loss: 0.0282 - val_mean_absolute_error: 0.1415\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.0063 - mean_absolute_error: 0.0588 - val_loss: 0.0255 - val_mean_absolute_error: 0.1326\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.0064 - mean_absolute_error: 0.0606 - val_loss: 0.0247 - val_mean_absolute_error: 0.1313\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.0060 - mean_absolute_error: 0.0577 - val_loss: 0.0253 - val_mean_absolute_error: 0.1309\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.0062 - mean_absolute_error: 0.0598 - val_loss: 0.0227 - val_mean_absolute_error: 0.1254\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.0058 - mean_absolute_error: 0.0573 - val_loss: 0.0240 - val_mean_absolute_error: 0.1300\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.0053 - mean_absolute_error: 0.0549 - val_loss: 0.0250 - val_mean_absolute_error: 0.1329\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.0055 - mean_absolute_error: 0.0548 - val_loss: 0.0233 - val_mean_absolute_error: 0.1256\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.0054 - mean_absolute_error: 0.0552 - val_loss: 0.0244 - val_mean_absolute_error: 0.1311\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.0051 - mean_absolute_error: 0.0537 - val_loss: 0.0278 - val_mean_absolute_error: 0.1396\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.0050 - mean_absolute_error: 0.0528 - val_loss: 0.0259 - val_mean_absolute_error: 0.1339\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.0049 - mean_absolute_error: 0.0523 - val_loss: 0.0265 - val_mean_absolute_error: 0.1373\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.0050 - mean_absolute_error: 0.0533 - val_loss: 0.0261 - val_mean_absolute_error: 0.1342\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.0053 - mean_absolute_error: 0.0545 - val_loss: 0.0248 - val_mean_absolute_error: 0.1325\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.0046 - mean_absolute_error: 0.0499 - val_loss: 0.0246 - val_mean_absolute_error: 0.1288\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.0046 - mean_absolute_error: 0.0519 - val_loss: 0.0245 - val_mean_absolute_error: 0.1274\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.0045 - mean_absolute_error: 0.0497 - val_loss: 0.0277 - val_mean_absolute_error: 0.1371\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.0049 - mean_absolute_error: 0.0526 - val_loss: 0.0231 - val_mean_absolute_error: 0.1248\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.0040 - mean_absolute_error: 0.0464 - val_loss: 0.0241 - val_mean_absolute_error: 0.1281\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.0040 - mean_absolute_error: 0.0475 - val_loss: 0.0230 - val_mean_absolute_error: 0.1257\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.0035 - mean_absolute_error: 0.0433 - val_loss: 0.0237 - val_mean_absolute_error: 0.1270\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.0035 - mean_absolute_error: 0.0429 - val_loss: 0.0231 - val_mean_absolute_error: 0.1260\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.0034 - mean_absolute_error: 0.0428 - val_loss: 0.0249 - val_mean_absolute_error: 0.1319\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.0034 - mean_absolute_error: 0.0427 - val_loss: 0.0288 - val_mean_absolute_error: 0.1427\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.0034 - mean_absolute_error: 0.0432 - val_loss: 0.0239 - val_mean_absolute_error: 0.1260\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.0035 - mean_absolute_error: 0.0435 - val_loss: 0.0265 - val_mean_absolute_error: 0.1375\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.0033 - mean_absolute_error: 0.0423 - val_loss: 0.0249 - val_mean_absolute_error: 0.1331\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.0029 - mean_absolute_error: 0.0388 - val_loss: 0.0255 - val_mean_absolute_error: 0.1334\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.0028 - mean_absolute_error: 0.0379 - val_loss: 0.0258 - val_mean_absolute_error: 0.1343\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.0028 - mean_absolute_error: 0.0375 - val_loss: 0.0261 - val_mean_absolute_error: 0.1350\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.0027 - mean_absolute_error: 0.0375 - val_loss: 0.0263 - val_mean_absolute_error: 0.1367\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.0027 - mean_absolute_error: 0.0372 - val_loss: 0.0261 - val_mean_absolute_error: 0.1354\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.0026 - mean_absolute_error: 0.0366 - val_loss: 0.0273 - val_mean_absolute_error: 0.1391\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.0026 - mean_absolute_error: 0.0370 - val_loss: 0.0255 - val_mean_absolute_error: 0.1333\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.0024 - mean_absolute_error: 0.0349 - val_loss: 0.0254 - val_mean_absolute_error: 0.1333\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.0024 - mean_absolute_error: 0.0347 - val_loss: 0.0264 - val_mean_absolute_error: 0.1368\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.0023 - mean_absolute_error: 0.0338 - val_loss: 0.0264 - val_mean_absolute_error: 0.1363\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.0023 - mean_absolute_error: 0.0341 - val_loss: 0.0266 - val_mean_absolute_error: 0.1372\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.0023 - mean_absolute_error: 0.0340 - val_loss: 0.0264 - val_mean_absolute_error: 0.1366\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.0023 - mean_absolute_error: 0.0341 - val_loss: 0.0267 - val_mean_absolute_error: 0.1368\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.0024 - mean_absolute_error: 0.0341 - val_loss: 0.0261 - val_mean_absolute_error: 0.1345\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.0022 - mean_absolute_error: 0.0327 - val_loss: 0.0273 - val_mean_absolute_error: 0.1387\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.0022 - mean_absolute_error: 0.0329 - val_loss: 0.0269 - val_mean_absolute_error: 0.1373\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.0022 - mean_absolute_error: 0.0325 - val_loss: 0.0269 - val_mean_absolute_error: 0.1375\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.0022 - mean_absolute_error: 0.0324 - val_loss: 0.0268 - val_mean_absolute_error: 0.1370\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0320 - val_loss: 0.0263 - val_mean_absolute_error: 0.1359\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0266 - val_mean_absolute_error: 0.1367\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0317 - val_loss: 0.0268 - val_mean_absolute_error: 0.1372\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0271 - val_mean_absolute_error: 0.1379\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0316 - val_loss: 0.0270 - val_mean_absolute_error: 0.1375\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.0021 - mean_absolute_error: 0.0312 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0313 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0312 - val_loss: 0.0273 - val_mean_absolute_error: 0.1387\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0310 - val_loss: 0.0271 - val_mean_absolute_error: 0.1380\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0310 - val_loss: 0.0272 - val_mean_absolute_error: 0.1384\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0309 - val_loss: 0.0272 - val_mean_absolute_error: 0.1384\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0309 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0309 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0309 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1380\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1381\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0308 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.0020 - mean_absolute_error: 0.0307 - val_loss: 0.0271 - val_mean_absolute_error: 0.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f9eb7b82a10>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split = 0.2, epochs = 200, batch_size = 16, callbacks = [early_stop, lr_reduce],\n",
    "          verbose = 2)\n",
    "# model.save_weights('../weights/t1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state = 1, scoring = 'neg_mean_absolute_error').fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0040\n                \n                    &plusmn; 0.0003\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxdO\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.85%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0037\n                \n                    &plusmn; 0.0005\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxaaN\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0037\n                \n                    &plusmn; 0.0005\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                minaaN\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 81.87%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0035\n                \n                    &plusmn; 0.0005\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                mindO\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 82.66%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0003\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint3\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 83.40%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0030\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                minssO\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 83.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0030\n                \n                    &plusmn; 0.0004\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint8\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 83.92%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0029\n                \n                    &plusmn; 0.0007\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxssO\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 85.28%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0026\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                minsF\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 85.60%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0025\n                \n                    &plusmn; 0.0008\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint2\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 87.66%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0020\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint6\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 87.77%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0020\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxsF\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.44%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0004\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxsOH\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.62%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0006\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHsOH\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.72%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0004\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint10\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.21%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0004\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxHBint5\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.27%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0003\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                MDEC-34\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.31%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0005\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                maxdssC\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.42%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                minsssN\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.46%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0002\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                SHsOH\n            </td>\n        </tr>\n    \n    \n        \n            <tr style=\"background-color: hsl(120, 100.00%, 89.46%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 709 more &hellip;</i>\n                </td>\n            </tr>\n        \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(perm, feature_names = head.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ai-base",
   "language": "python",
   "display_name": "AI-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}